这个系列将记录下本人平时在深度学习方面觉得实用的一些trick，可能会包括性能提升和工程优化等方面。
该系列的代码会更新到Github
这张图就很清晰地阐述整个推荐系统的流程：
从百万量级的视频库，根据用户的特征及上下文信息，通过召回模型，筛选出用户可能感兴趣的少量视频，称为候选集(百量级)；
接着，再通过排序模型，将上一步的候选集，进行排序，最终呈现给用户。
数据类别不均衡是很多场景任务下会遇到的一种问题。比如NLP中的命名实体识别NER，文本中许多都是某一种或者几种类型的实体，比如无需识别的不重要实体；又或者常见的分类任务，大部分数据的标签都是某几类。
而我们又无法直接排除这些很少的类别的数据，因为这些类别也很重要，仍然需要模型去预测这些类别。
有时会从数据层面缓解这种类别不均衡带来的影响，主要是过采样和欠采样。
过采样：对于某些类别数据比较少，对它们进行重复采样，以达到相对平衡，重复采样的时候，有时也会对数据加上一点噪声；
欠采样：对于某些类别数据特别多，只使用部分数据，抛弃一些数据；
过采样可能导致这些类别产生过拟合的现象，而欠采样则容易导致模型的泛化性变差。
另外，比较常用的则是结合ensemble方法，则将数据切分为N部分，每部分都包含数据少的类别的所有样本和数据多的类别的部分样本，训练N个模型，最后进行集成。
缺点是，使用ensemble则会提高部署成本和带来性能问题。
版权声明：本文为CSDN博主「我就算饿死也不做程序员」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/sgyuanshi/article/details/127796507
上面也提到：召回网络的目标即可以理解为预测对于一个用户，在当前的上下文场景下，观看每个视频的概率。
那么，对于每个样本来说，所有视频都可能是正样本。假如有100W个视频，那么召回模型就变成一个100W分类模型了，这显然带来了很大的训练难度。
所以，就需要用到负采样了，论文这里讲得比较模糊，大概思路就是：
ID特征经过embedding层和其他dense特征拼接，作为输入层；
接着，是共享网络层share-bottom，一般称为硬参数共享(hard parameter sharing)。这是通过底层的共享网络来实现不同task信息之间的共享；
然后，是专家网络层，即每个task有自己独立的网络层；
最后，每个task的专家网络层输出对应的预测值。